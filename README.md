# DB-SQL-Yelp


1. This is a Database Management project, based in SQL.
   The repository is initiated on the 1st of April, 2024 and will be developed over the course of the next month.
   

Team Members -
Github Repository
○ Vidit Sheth (G27981166) - ViditSheth77
○ Avani Rao (G45297503) - Avani032000 
○ Karthik Iyer (G36721984) - karthikiyer365
○ Akash Poddar (G34554396) - Akash69420
Project Name : Data analysis for YELP reviews
We are embarking on a comprehensive data analysis project utilizing the PostgreSQL database management system, featuring Yelp database with 4 json files. 
Data found at: https://www.yelp.com/dataset

All Files and Folders at: https://drive.google.com/drive/folders/1lacpglVoNXucHOwbDCY5j2u6KAjcRwPu?usp=sharing
Data, Processing : initial_cleaning_file.ipynb 
SQL and Spark: YELP_SQL_DBanalysis.ipynb 


The data isin the form of json files with folling types of info:
1. json_business: business information(name, reviews for the business, address, rating(out of 5) etc.)
2. json_reviews: reviews text, rating, date of rating etc,
3. json_tip: user_id, business_id, date, compliment_count, etc.
4. json_user: user info(user name, friends, number of reviews) etc.
5. json_checkin: working hours of restaurant


Scope of project:
• The primary objective of the data analysis project is to extract actionable insights from the Yelp database. These insights may include:
- Understanding customer reviews
• We shall perform SQL queries for data extraction, transformation, and aggregation.
• Statistical analysis to identify correlations and trends.
• Data visualization techniques (charts, graphs, dashboards) for presenting insights.
By utilizing Apache Spark through PySpark we aim to conduct insightful data analysis to uncover trends, patterns, and valuable insights.
• Technology: SQL, python notebook, Dashboard, Matplotlib,Seaborn, Plotly.
• Data Source: The following is the data source which we are gonna use in the project.

• Distribution of work :
• Data Collection - Avani Rao
Gathering the data required for the project. This involves sourcing the dataset from Kaggle and ensuring it is complete, accurate, and ready for analysis. 
• Data Cleaning - Karthik Iyer
Setting up a pyspark environment and sampling the data based on analytical requirements
• Database setup - Karthik Iyer
Setting up the database. This involves configuring the PostgreSQL/MySQL database management system and ensuring that the data is correctly imported into the database.
• Data EDA – Karthik Iyer
Exploring the data to understand its characteristics and cleaning the data to ensure accuracy and consistency
• SQL Querying - Vidit Sheth
Vidit will utilize SQL to query the database for specific data needed for analysis. This task is foundational to the project as it enables the team to extract meaningful information from the dataset.
• Analytical Insights - Avani Rao
Avani will conduct in-depth data analysis to derive meaningful insights from the dataset. This step provides actionable insights. 
Utilizing python libraries such as matplotlib, seaborn, plotly etc to derive visualizaton from SQL queries for analysis and interpretation.
• Report and Presentation - Akash Poddar
In addition to generating analytical insights, is tasked with compiling the project report and preparing the presentation. This involves documenting the methodologies, analyses, findings, and ecommendations in a structured report.
